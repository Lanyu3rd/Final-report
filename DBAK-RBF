import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, silhouette_score, mean_absolute_error
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import SVR
import random
from sklearn.cluster import KMeans
import time
from sklearn.preprocessing import StandardScaler
from tslearn.preprocessing import TimeSeriesScalerMeanVariance, TimeSeriesResampler
from tslearn.clustering import TimeSeriesKMeans
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior() 
starttime = time.time()
df = pd.read_csv('C:/Users/nchu003/Desktop/dataset/AAPL.csv', usecols=[4])
dataset = df['Close'].values
dataset = dataset.astype('float32')

fig, ax = plt.subplots(figsize=(8,5))
df['Close'].plot(color='r')
plt.ylabel("price") # y label
plt.xlabel("days") # x label
plt.title("AAPL",fontsize=20)
starttime = time.time()
dataset = pd.read_csv('C:/Users/nchu003/Desktop/dataset/AAPL.csv', usecols=[4])
dataset = dataset.values
dataset = dataset.astype('float32')


def select_set(start, training_day, testing_day):
    training_set = dataset[start:start+training_day]
    testing_set = dataset[start+training_day:(start+training_day)+testing_day]
    return training_set, testing_set

def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        b = dataset[i + look_back, 0]
        dataX.append(a)
        dataY.append(b)
    return np.array(dataX), np.array(dataY)


# training_set, testing_set = select_set(0, 82, 42)
scaler = MinMaxScaler()
# dataset = scaler.fit_transform(dataset)
training_set, _ = select_set(0, 176, 42)
testing_set = dataset[176:, ]
training_set = scaler.fit_transform(training_set)
testing_set = scaler.fit_transform(testing_set)

#############creat time-series############
train_X = []
train_Y = []
test_X = []
test_Y = []

work_days = 22
a = list(range(176-work_days))
b = list(range(76-work_days))
training_days = a[-1] + 1
testing_days = b[-1] + 1

for i in range(len(a)):
    start = a[i]
    end = work_days
    train_X.append(training_set[start:start+end].T)
    train_Y.append(training_set[start+end])


for j in range(len(b)):
    start = b[j]
    end = work_days
    test_X.append(testing_set[start:start+end].T)
    test_Y.append(testing_set[start+end])


train_X = np.array(train_X)
train_Y = np.array(train_Y)
test_X = np.array(test_X)
test_Y = np.array(test_Y)



train_X = np.reshape(train_X, (len(a), work_days))
test_X = np.reshape(test_X, (len(b), work_days))


data = pd.read_csv('C:/Users/nchu003/Desktop/dataset/AAPL.csv', usecols=[1, 2, 3, 4, 5, 6])
##########k-mean#########
# total_X = np.concatenate((train_X, test_X), axis=0)

kmean_X = []
for i in range(len(a)):
    total_X = train_X
    kmean_X_train_min = np.min(total_X[i, :])
    kmean_X_train_max = np.max(total_X[i, :])
    kmean_trainX = (total_X[i, :] - kmean_X_train_min) / (kmean_X_train_max - kmean_X_train_min)
    kmean_X.append(kmean_trainX)
kmean_X = np.array(kmean_X)


##########silhouette coefficient to choose k clusters##########
Scores = []
for k in range(4, 11):
    train_kmean = KMeans(n_clusters=k).fit(data)
    Scores.append(silhouette_score(data, train_kmean.labels_, metric='euclidean'))

print(Scores)
se_clusters = range(4, 11)
plt.xlabel('k')
plt.ylabel('silhouette coefficient')
plt.plot(se_clusters, Scores, 'o-', color='red')
plt.show()

########## parameter ##########

nodes = int(input('k='))
lr = 0.0003
training_kmean = KMeans(n_clusters=nodes).fit(kmean_X)
train_center = training_kmean.cluster_centers_
# Keep only 50 time series
X_train = TimeSeriesScalerMeanVariance().fit_transform(train_X)
# Make time series shorter
X_train = TimeSeriesResampler(sz=22).fit_transform(X_train)
sz = X_train.shape[1]

print("DBA k-means")
dba_km = TimeSeriesKMeans(n_clusters=7,
                          n_init=2,
                          metric="dtw",
                          verbose=True,
                          max_iter_barycenter=10)
y_pred = dba_km.fit_predict(X_train)
class RBF():
    def __init__(self, hidden_nodes, train_X, train_Y, test_X, test_Y, batch):
        self.hidden_nodes = hidden_nodes
        self.train_X = train_X
        self.train_Y = train_Y
        self.test_X = test_X
        self.test_Y = test_Y
        self.batch = batch
    def fit(self):
        n_input = self.train_X.shape[1]
        n_output = self.train_Y.shape[1]
        X = tf.placeholder(tf.float32, [self.batch,n_input], name='X')
        Y = tf.placeholder(tf.float32, [self.batch,n_output], name='Y')

        center = tf.Variable(train_center, name='center')
        gamma = tf.Variable(tf.random_normal([1, self.hidden_nodes]), name='gamma')
        gamma_2 = tf.square(gamma)

        w = tf.Variable(tf.random_normal([self.hidden_nodes, n_output]), name='w')
        b = tf.Variable(tf.random_normal([self.batch, n_output]), name='b')

        dist = tf.reduce_sum(tf.square(tf.subtract(tf.expand_dims(X, 1), center)), 2)

        rbf_G = tf.exp(tf.multiply(-1.0, tf.divide(dist, tf.multiply(2.0, gamma_2))))
        rbf_MQ = tf.sqrt(1 + tf.multiply(dist,gamma_2))
        rbf_IQ = 1 / (1 + tf.multiply(dist,gamma_2))
        rbf_IMQ = 1 / tf.sqrt((1 + tf.multiply(dist, gamma_2)))

        y_pred = tf.matmul(rbf_G, w)

        cost = tf.losses.mean_squared_error(Y, y_pred)
        train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)

        saver = tf.train.Saver()
        with tf.Session() as sess:
            tf.global_variables_initializer().run()
            learning_rate_list = []
            mean_error_list = []
            rmse_list = []
            train_loss_list = []
            test_loss_list = []

            for epoch in range(501):
                y_train, pred_train_y = [], []
                ori_y, pred_y = [], []
                train_error, test_error = [], []
                test_error_percentage = []
                error_square = []
                train_list = []
                test_list = []


                for batch in range(len(train_X)):
                    train_x = np.reshape(self.train_X[batch, :], (1, work_days))
                    train_y = np.reshape(self.train_Y[batch, :], (1, 1))

                    feed = {X: train_x, Y: train_y}
                    sess.run(train_op, feed_dict=feed)
                    total_loss = sess.run(cost, feed_dict=feed)
                    train_list.append(total_loss)
                    y_train.append(train_y)
                    pred_train_y.append(sess.run(y_pred, feed_dict=feed))
                    train_err = abs(pred_train_y[batch] - y_train[batch])
                    train_error.append(train_err)


                for test_batch in range(len(test_X)):
                    test_x = np.reshape(self.test_X[test_batch, :], (1, work_days))
                    test_y = np.reshape(self.test_Y[test_batch, :], (1, 1))

                    feed = {X: test_x, Y: test_y}
                    total_loss = sess.run(cost, feed_dict=feed)
                    test_list.append(total_loss)
                    ori_y.append(test_y)
                    pred_y.append(sess.run(y_pred, feed_dict=feed))

                    test_err = abs(pred_y[test_batch] - ori_y[test_batch])
                    err_square = (pred_y[test_batch] - ori_y[test_batch])**2
                    test_error.append(test_err)
                    error_square.append(err_square)

                train_MAE = np.mean(train_error)
                test_MAE = np.mean(test_error)
                root_mean_square_error = np.sqrt(np.mean(error_square))
                mean_error_list.append(test_MAE)
                rmse_list.append(root_mean_square_error)

                train_loss_list.append(np.mean(np.array(train_list)))
                test_loss_list.append(np.mean(np.array(test_list)))

                trainPredict = scaler.inverse_transform(np.reshape(y_train, (-1, 1)))
                train_YY = scaler.inverse_transform(np.reshape(pred_train_y, (-1, 1)))
                testPredict = scaler.inverse_transform(np.reshape(pred_y, (-1, 1)))
                test_Y = scaler.inverse_transform(np.reshape(ori_y, (-1, 1)))

                train_real_err = (abs(train_YY - trainPredict)) / train_YY
                train_real_MAPE = np.mean(train_real_err) * 100
                test_real_err = (abs(test_Y - testPredict)) / test_Y
                test_real_MAPE = np.mean(test_real_err) * 100
                Error_rate = (np.reshape(testPredict, (1, -1)) - np.reshape(test_Y, (1, -1))) / np.reshape(test_Y, (1, -1))

                print('test_MAE:', test_MAE)

                if epoch % 100 == 0 and epoch != 0:

                    print('Predict price:', np.reshape(testPredict, (1, -1)))
                    print('Real price:', np.reshape(test_Y, (1, -1)))
                    print('Error rate:', Error_rate * 100, '%')

model = RBF(nodes, train_X, train_Y, test_X, test_Y, 1)
model.fit()
